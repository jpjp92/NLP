{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPT(Generative Pre-Training) Implementation\n",
        "\n",
        "---\n",
        "### **Description**\n",
        "\n",
        "- Model Architecture:\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCN9jO%2FbtsmiDJHWRI%2Fy9vSNfNEWCIsGzebxHBXPK%2Fimg.png\"> </img> <br>\n",
        "\n",
        "     Figure1. GPT Architecture and brief description of 4 different tasks(Radford, A. et. al, 2018)\n",
        "<br>\n",
        "\n",
        "- Dataset:\n",
        "    - Paper : WikiQA: A Challenge Dataset for Open-Domain Question Answering\n",
        "    <br>\n",
        "\n",
        "- System Environment:\n",
        "    - Goolge Colab Pro Plus GPU: A100\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Reference**\n",
        "\n",
        "[1] \"GPT(Generative Pre-Training) Implementation\", cchyun, accessed 2023 04 11, https://paul-hyun.github.io/gpt-01/.\n",
        "\n",
        "[2] \"[Paper Review] GPT : Generative Pre-training / OpenAI NLP\", 구름위의공룡, accessed 2023 05 22, https://mr-waguwagu.tistory.com/27.\n",
        "\n",
        "[3] \"GPT1 Paper review Improving Language Understanding\n",
        "by Generative Pre-Training\", 이수진의블로그, accessed 2023 05 22, https://lsjsj92.tistory.com/617.\n",
        "\n",
        "[3] Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language understanding by generative pre-training.\n",
        "\n",
        "[4] Yang, Y., Yih, W. T., & Meek, C. (2015, September). Wikiqa: A challenge dataset for open-domain question answering. In Proceedings of the 2015 conference on empirical methods in natural language processing (pp. 2013-2018).\n"
      ],
      "metadata": {
        "id": "_RJALmZ4v8HM"
      },
      "id": "_RJALmZ4v8HM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Library"
      ],
      "metadata": {
        "id": "SemMAOYcQj6I"
      },
      "id": "SemMAOYcQj6I"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bik-vd3_hWwA",
        "outputId": "c675b3f5-3fa7-42dc-bcd4-97416aa115c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ],
      "source": [
        "# install Sentencepiece library\n",
        "pip install sentencepiece"
      ],
      "id": "Bik-vd3_hWwA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Library"
      ],
      "metadata": {
        "id": "-YeR6Lu5Qgy5"
      },
      "id": "-YeR6Lu5Qgy5"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "71b905a1-cf85-4e05-9e33-ffc7ba24b082"
      },
      "outputs": [],
      "source": [
        "# Sentencepiece\n",
        "import sentencepiece as spm\n",
        "\n",
        "# Torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Tools\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Optional\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "from random import random, randrange, randint, shuffle, choice"
      ],
      "id": "71b905a1-cf85-4e05-9e33-ffc7ba24b082"
    },
    {
      "cell_type": "code",
      "source": [
        "# For Colab Environment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOlVK-uwQcBq",
        "outputId": "29616042-4efa-4354-a652-e1563f05768a"
      },
      "id": "KOlVK-uwQcBq",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "edb7269b-0151-4c6e-927e-077faa0f0643"
      },
      "outputs": [],
      "source": [
        "# Tokenization make a vocab using WikiQA dataset\n",
        "\n",
        "corpus = \"/content/drive/MyDrive/WikiQA.txt\"\n",
        "prefix = \"WikiQA\"\n",
        "vocab_size = 12000\n",
        "spm.SentencePieceTrainer.train(\n",
        "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" +\n",
        "    \" --model_type=bpe\" +\n",
        "    \" --max_sentence_length=999999\" + # Max length of sentence\n",
        "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
        "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
        "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
        "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
        "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # User defined token"
      ],
      "id": "edb7269b-0151-4c6e-927e-077faa0f0643"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21e0599d-774d-4060-8395-b499ebb30609",
        "outputId": "74cdf225-526a-4fd8-f6e1-a7c7b66f8ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i love soccer, and pizza\n",
            "['▁i', '▁love', '▁soc', 'cer', ',', '▁and', '▁p', 'iz', 'za']\n",
            "[537, 3893, 4667, 1246, 11969, 42, 31, 229, 7489]\n",
            "i love soccer, and pizza\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Using Vocab test sentence into pieces\n",
        "\n",
        "vocab_file = \"WikiQA.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)\n",
        "\n",
        "lines = [\n",
        "  'i love soccer, and pizza'\n",
        "]\n",
        "for line in lines:\n",
        "    pieces = vocab.encode_as_pieces(line)\n",
        "    ids = vocab.encode_as_ids(line)\n",
        "    a = vocab.Decode(ids)\n",
        "    print(line)\n",
        "    print(pieces)\n",
        "    print(ids)\n",
        "    print(a)\n",
        "    print()"
      ],
      "id": "21e0599d-774d-4060-8395-b499ebb30609"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Configuration\n",
        "- \"n_dec_vocab\": length of vocab\n",
        "- \"n_dec_seq\": 256,\n",
        "- \"n_layer\": 12,\n",
        "- \"d_hidn\": 768,\n",
        "- \"i_pad\": 0,\n",
        "- \"d_ff\": 1024,\n",
        "- \"n_head\": 16,\n",
        "- \"d_head\": 48,\n",
        "- \"dropout\": 0.1,\n",
        "- \"layer_norm_epsilon\": 1e-12"
      ],
      "metadata": {
        "id": "4S3zFpQLVl-6"
      },
      "id": "4S3zFpQLVl-6"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3738aa79-6cae-42a2-9a84-25bee00ba069"
      },
      "outputs": [],
      "source": [
        "# Define Configuration\n",
        "class Config(dict):\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "id": "3738aa79-6cae-42a2-9a84-25bee00ba069"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2bcd19a-135e-4a15-9a50-dcca01603509",
        "outputId": "32e7735f-266b-47ba-db47-53ea2d42738d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_dec_vocab': 12007, 'n_dec_seq': 256, 'n_layer': 12, 'd_hidn': 768, 'i_pad': 0, 'd_ff': 1024, 'n_head': 16, 'd_head': 48, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ]
        }
      ],
      "source": [
        "# Set Configuration\n",
        "config = Config({\n",
        "    \"n_dec_vocab\": len(vocab),\n",
        "    \"n_dec_seq\": 256,\n",
        "    \"n_layer\": 12,\n",
        "    \"d_hidn\": 768,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 16,\n",
        "    \"d_head\": 48,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ],
      "id": "b2bcd19a-135e-4a15-9a50-dcca01603509"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Sinusoidal Positional Encoding\n",
        "- Sinusoidal encoding table\n",
        "- attention pad mask\n",
        "- attention decoder mask\n",
        "- scale dot product attention\n",
        "- multihead attention\n",
        "- feed forward\n",
        "- decoder layer\n",
        "- decoder"
      ],
      "metadata": {
        "id": "Ai7UXMCvTUUo"
      },
      "id": "Ai7UXMCvTUUo"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "610ebe8a-1815-4b35-9779-453ca6b636c9"
      },
      "outputs": [],
      "source": [
        "# Sinusoidal Positional Encoding\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
        "\n",
        "    return sinusoid_table\n",
        "\n",
        "\n",
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  #\n",
        "    return pad_attn_mask\n",
        "\n",
        "\n",
        "\"\"\" attention decoder mask \"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    return subsequent_mask\n",
        "\n",
        "\n",
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output\n"
      ],
      "id": "610ebe8a-1815-4b35-9779-453ca6b636c9"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "da7f3e03-19ab-4c34-9b7e-a06c3ab136ac"
      },
      "outputs": [],
      "source": [
        "\"\"\" decoder layer \"\"\"\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "\n",
        "    def forward(self, dec_inputs, self_attn_mask):\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
        "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
        "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(self_att_outputs)\n",
        "        ffn_outputs = self.layer_norm3(self_att_outputs + ffn_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        return ffn_outputs, self_attn_prob"
      ],
      "id": "da7f3e03-19ab-4c34-9b7e-a06c3ab136ac"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "d386adc2-519c-47f1-b613-010878d0ca5e"
      },
      "outputs": [],
      "source": [
        "\"\"\" decoder \"\"\"\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "\n",
        "    def forward(self, dec_inputs):\n",
        "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "\n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
        "\n",
        "        self_attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq)\n",
        "            dec_outputs, self_attn_prob = layer(dec_outputs, dec_self_attn_mask)\n",
        "            self_attn_probs.append(self_attn_prob)\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)]\n",
        "        return dec_outputs, self_attn_probs"
      ],
      "id": "d386adc2-519c-47f1-b613-010878d0ca5e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPT\n",
        "- Define GPT, GPT pretrain\n",
        "- Create pretrain data per doc, pretrain data\n",
        "- Make a pretrain data as json file"
      ],
      "metadata": {
        "id": "trwQs9rNTrET"
      },
      "id": "trwQs9rNTrET"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "37d5e28c-dd4c-4929-b892-2aadc6d69723"
      },
      "outputs": [],
      "source": [
        "\"\"\" gpt \"\"\"\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.decoder = Decoder(self.config)\n",
        "\n",
        "    def forward(self, dec_inputs):\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        dec_outputs, dec_self_attn_probs = self.decoder(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        return dec_outputs, dec_self_attn_probs\n",
        "\n",
        "    def save(self, epoch, loss, path):\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            \"state_dict\": self.state_dict()\n",
        "        }, path)\n",
        "\n",
        "    def load(self, path):\n",
        "        save = torch.load(path)\n",
        "        self.load_state_dict(save[\"state_dict\"])\n",
        "        return save[\"epoch\"], save[\"loss\"]"
      ],
      "id": "37d5e28c-dd4c-4929-b892-2aadc6d69723"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "22bed513-1313-4533-be62-d23a3ffe5af8"
      },
      "outputs": [],
      "source": [
        "\"\"\" GPT pretrain \"\"\"\n",
        "class GPTPretrain(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.gpt = GPT(self.config)\n",
        "        # lm\n",
        "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_dec_vocab, bias=False)\n",
        "        self.projection_lm.weight = self.gpt.decoder.dec_emb.weight\n",
        "\n",
        "    def forward(self, dec_inputs):\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        dec_outputs, dec_self_attn_probs = self.gpt(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab)\n",
        "        logits_lm = self.projection_lm(dec_outputs)\n",
        "        # (bs, n_dec_seq - 1, n_dec_vocab), (bs, n_output), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        return logits_lm, dec_self_attn_probs"
      ],
      "id": "22bed513-1313-4533-be62-d23a3ffe5af8"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "034e8e29-64a3-4b28-b6dd-2dedca93a8ff"
      },
      "outputs": [],
      "source": [
        "\"\"\" create pretrain data per doc \"\"\"\n",
        "def create_pretrain_instances(doc, n_seq):\n",
        "    # for [BOS], [EOS]\n",
        "    max_seq = n_seq - 2\n",
        "    tgt_seq = max_seq\n",
        "    instances = []\n",
        "    a_end=0\n",
        "    for i in range(len(doc)):\n",
        "        if doc[i] =='▁,':\n",
        "            a_end = i\n",
        "\n",
        "    tokens_a =[\"[BOS]\"] + doc[:a_end] + [\"[EOS]\"]\n",
        "    tokens_b = [\"[BOS]\"] + doc[a_end+1: ] + [\"[EOS]\"]\n",
        "    # if len(tokens_a)>len(tokens_b):\n",
        "    #     a= [0] * (len(tokens_a)-len(tokens_b))\n",
        "    # else:\n",
        "    #     a= [0] * (len(tokens_b)-len(tokens_a))\n",
        "    # for i in range(len(doc)):\n",
        "    #     tokens.append(doc[i]) # line\n",
        "\n",
        "    instance = {\n",
        "        \"tokens_a\": tokens_a,\n",
        "        \"tokens_b\":tokens_b\n",
        "    }\n",
        "    instances.append(instance)\n",
        "    return instances"
      ],
      "id": "034e8e29-64a3-4b28-b6dd-2dedca93a8ff"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "6fbbb9f3-1b61-4215-8fdb-8cd50fd625e1"
      },
      "outputs": [],
      "source": [
        "\"\"\" Create pretrain data  \"\"\"\n",
        "def make_pretrain_data(vocab, in_file, out_file, n_seq):\n",
        "    line_cnt = 0\n",
        "    with open(in_file, \"r\", encoding='UTF8') as in_f:\n",
        "        for line in in_f:\n",
        "            line_cnt += 1\n",
        "\n",
        "    docs = []\n",
        "    with open(in_file, \"r\", encoding='UTF8') as f:\n",
        "        doc = []\n",
        "        with tqdm(total=line_cnt, desc=f\"Loading\") as pbar:\n",
        "            for i, line in enumerate(f):\n",
        "                line = line.strip()\n",
        "                if line == \"\":\n",
        "                    if 0 < len(doc):\n",
        "                        docs.append(doc)\n",
        "                        doc = []\n",
        "                        # In order to reduce size of the memory only used 100k\n",
        "                        if 100000 < len(docs): break\n",
        "                else:\n",
        "                    pieces = vocab.encode_as_pieces(line)\n",
        "                    if 0 < len(pieces):\n",
        "                        doc.append(pieces)\n",
        "                pbar.update(1)\n",
        "        if doc:\n",
        "            docs.append(doc)\n",
        "    docs = sum(docs,[])\n",
        "    with open(out_file, \"w\", encoding='UTF8') as out_f:\n",
        "        with tqdm(total=len(docs), desc=f\"Making\") as pbar:\n",
        "            for i, doc in enumerate(docs):\n",
        "                instances = create_pretrain_instances(doc, n_seq)\n",
        "                for instance in instances:\n",
        "                    print(instance, file=out_f)\n",
        "                        # out_f.write(instance)\n",
        "                        # out_f.write(\"\\n\")\n",
        "                    pbar.update(1)\n"
      ],
      "id": "6fbbb9f3-1b61-4215-8fdb-8cd50fd625e1"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0191623-fbda-48bd-9f05-2c383906935c",
        "outputId": "45b3db9b-70eb-4b9b-809e-b7ef2424150f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: 100%|██████████| 63282/63282 [00:06<00:00, 10444.88it/s]\n",
            "Making: 100%|██████████| 63282/63282 [00:00<00:00, 89025.96it/s]\n"
          ]
        }
      ],
      "source": [
        "# make pretrain data as json file\n",
        "in_file = \"/content/drive/MyDrive/WikiQA.txt\"\n",
        "out_file = \"WikiQA.json\"\n",
        "\n",
        "n_seq = 256\n",
        "make_pretrain_data(vocab, in_file, out_file, n_seq)\n"
      ],
      "id": "e0191623-fbda-48bd-9f05-2c383906935c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrain dataset\n",
        "- Define pretrain dataset, pretrain data collate function\n",
        "- Create pretrain dataloader"
      ],
      "metadata": {
        "id": "7HOS7BhKUd4T"
      },
      "id": "7HOS7BhKUd4T"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "4843cf96-51c7-437a-8235-394878c30d78"
      },
      "outputs": [],
      "source": [
        "\"\"\" pretrain datatset \"\"\"\n",
        "class PretrainDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.sentences = []\n",
        "        self.label = []\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\", encoding='UTF8') as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\", encoding='UTF8') as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "\n",
        "                line = json.dumps(line)\n",
        "                instance = eval(json.loads(line))\n",
        "                tokens_a = [vocab.piece_to_id(p) for p in instance[\"tokens_a\"]]\n",
        "                tokens_b = [vocab.piece_to_id(p) for p in instance[\"tokens_b\"]]\n",
        "                if len(tokens_a) > len(tokens_b):\n",
        "                    a = [0]*(len(tokens_a) - len(tokens_b))\n",
        "                    tokens_b = tokens_b +a\n",
        "\n",
        "                else:\n",
        "                    a = [0]*(len(tokens_b) - len(tokens_a))\n",
        "                    tokens_a = tokens_a +a\n",
        "                self.sentences.append(tokens_a)\n",
        "                self.label.append(tokens_b)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        assert len(self.sentences) == len(self.label)\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.sentences[item]),\n",
        "                torch.tensor(self.label[item]),\n",
        "                torch.tensor(item))"
      ],
      "id": "4843cf96-51c7-437a-8235-394878c30d78"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "db4a8338-40fa-4edd-9563-28c8a90f9ff5"
      },
      "outputs": [],
      "source": [
        "\"\"\" pretrain data collate_fn \"\"\"\n",
        "def pretrin_collate_fn(inputs):\n",
        "    dec_inputs,labels,item = list(zip(*inputs))\n",
        "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=0)\n",
        "    batch = [\n",
        "        dec_inputs,\n",
        "        labels,\n",
        "        torch.stack(item, dim=0)\n",
        "    ]\n",
        "\n",
        "    return batch"
      ],
      "id": "db4a8338-40fa-4edd-9563-28c8a90f9ff5"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d3f1c24-ea8a-4fbb-9096-9689552599f9",
        "outputId": "ba2d4b61-9505-4470-dba7-8c7f3a044376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading WikiQA.json: 100%|██████████| 63282/63282 [00:07<00:00, 8339.79 lines/s]\n"
          ]
        }
      ],
      "source": [
        "\"\"\" pretrain dataloader \"\"\"\n",
        "batch_size = 64\n",
        "dataset = PretrainDataSet(vocab, \"WikiQA.json\")\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True , collate_fn=pretrin_collate_fn)"
      ],
      "id": "0d3f1c24-ea8a-4fbb-9096-9689552599f9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training\n",
        "- Define training steps per epoch\n",
        "- Set device and Hyperparameter\n",
        "- Train GPT Model"
      ],
      "metadata": {
        "id": "R9xltWf7U21h"
      },
      "id": "R9xltWf7U21h"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "8b6459bb-23e8-42b5-9139-41549498e0db"
      },
      "outputs": [],
      "source": [
        "\"\"\" Train model per epoch \"\"\"\n",
        "def train_epoch(config, epoch, model, criterion_lm, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    # with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "    for i, value in enumerate(train_loader):\n",
        "        dec_inputs,labels_lm,_ = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(dec_inputs)\n",
        "\n",
        "        logits_lm = outputs[0]\n",
        "        # print(logits_lm.shape)\n",
        "        loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), labels_lm.view(-1))\n",
        "\n",
        "        losses.append(loss_lm.cpu().detach().numpy())\n",
        "\n",
        "        loss_lm.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Loss: {loss_lm:.3f} , Perplexity: {np.exp(loss_lm.item())}\")\n",
        "            # pbar.update(1)\n",
        "            # pbar.set_postfix_str(f\"Loss: {loss_lm:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "id": "8b6459bb-23e8-42b5-9139-41549498e0db"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4edb878f-156d-474f-817f-3dbb6bf41ed6",
        "outputId": "73fed6ea-f1c6-445d-b54d-9a196cd094eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_dec_vocab': 12007, 'n_dec_seq': 256, 'n_layer': 12, 'd_hidn': 768, 'i_pad': 0, 'd_ff': 1024, 'n_head': 16, 'd_head': 48, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda')}\n"
          ]
        }
      ],
      "source": [
        "# set device and hyperparameters\n",
        "\n",
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "betas=(0.9, 0.999)\n",
        "weight_decay = 0.01\n",
        "n_epoch = 20"
      ],
      "id": "4edb878f-156d-474f-817f-3dbb6bf41ed6"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c939b240-e506-4b0c-a893-4d13bc8f6b23",
        "outputId": "79f7978f-76f2-4c45-eb1e-ae9f66668d97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [02:12<42:03, 132.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 7.561 , Perplexity: 1921.7230009946895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [04:25<39:52, 132.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 7.270 , Perplexity: 1437.086196008035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [06:38<37:37, 132.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.217 , Perplexity: 67.84156138153749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [08:51<35:25, 132.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.097 , Perplexity: 60.17148002546026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [11:04<33:13, 132.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 5.562 , Perplexity: 260.3810634876626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [13:17<30:59, 132.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 5.046 , Perplexity: 155.34153794991076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [15:29<28:46, 132.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 5.893 , Perplexity: 362.38246792656236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [17:42<26:34, 132.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.553 , Perplexity: 94.91070991167621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [19:54<24:18, 132.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.816 , Perplexity: 45.44164156565117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [22:07<22:05, 132.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.114 , Perplexity: 61.183222202389054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [24:20<19:54, 132.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.784 , Perplexity: 43.973648430122864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [26:32<17:41, 132.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.470 , Perplexity: 32.1335408091607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [28:45<15:28, 132.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.837 , Perplexity: 46.36441998223824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [30:57<13:14, 132.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.114 , Perplexity: 61.17525810034126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [33:09<11:01, 132.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.044 , Perplexity: 57.081323890215835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [35:21<08:49, 132.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.982 , Perplexity: 19.718482927437783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [37:34<06:37, 132.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.084 , Perplexity: 59.3544494647348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [39:46<04:24, 132.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.460 , Perplexity: 31.824814782085085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [41:59<02:12, 132.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.567 , Perplexity: 35.412158632783104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [44:12<00:00, 132.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.554 , Perplexity: 34.966882445616186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train GPT Model\n",
        "model = GPTPretrain(config)\n",
        "# save_pretrain = \"save_gpt_pretrain_gpt.pth\"\n",
        "best_epoch, best_loss = 0, 0\n",
        "# if os.path.isfile(save_pretrain):\n",
        "#     best_epoch, best_loss = model.gpt.load(save_pretrain)\n",
        "#     print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\n",
        "#     best_epoch += 1\n",
        "\n",
        "model.to(config.device)\n",
        "\n",
        "criterion_lm = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = []\n",
        "offset = best_epoch\n",
        "for step in trange(n_epoch):\n",
        "    epoch = step + offset\n",
        "    loss = train_epoch(config, epoch, model, criterion_lm, optimizer, train_loader)\n",
        "    losses.append(loss)\n",
        "    # model.gpt.save(epoch, loss, save_pretrain)"
      ],
      "id": "c939b240-e506-4b0c-a893-4d13bc8f6b23"
    },
    {
      "cell_type": "code",
      "source": [
        "# Final loss of GPT\n",
        "print(f\"Loss fo GPT Model : {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi3envGa3gci",
        "outputId": "0fdf5e22-0831-40c1-f554-464be3729d0b"
      },
      "id": "Xi3envGa3gci",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss fo GPT Model : 3.131601333618164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39277a64-c508-4e09-97b4-3bcac4e9af77",
        "outputId": "bf1e0b38-b164-42ea-b1d8-ecc989cc1da1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lengthy ⁇ BOS ⁇  How a a directions of ocity force vectors related circular motio ⁇ SOS ⁇ ']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "test_inputs = vocab.encode('[BOS] How are the directions of the velocity and force vectors related in a circular motio[SOS]')\n",
        "test_inputs = torch.tensor([test_inputs]).to(config.device)\n",
        "out = model(test_inputs)\n",
        "[vocab.decode(i) for i in out[0].argmax(2).cpu().detach().tolist()]"
      ],
      "id": "39277a64-c508-4e09-97b4-3bcac4e9af77"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results\n",
        "- Show results in dataframe and graph"
      ],
      "metadata": {
        "id": "NACi_Mtyj6OF"
      },
      "id": "NACi_Mtyj6OF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Dataframe\n",
        "data = {\n",
        "    \"loss\": losses\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "1og2cYw_isSX",
        "outputId": "203c3aa4-ba60-42a5-e52b-32d1ea786cdc"
      },
      "id": "1og2cYw_isSX",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         loss\n",
              "0   13.630404\n",
              "1    7.435396\n",
              "2    5.694499\n",
              "3    4.939188\n",
              "4    4.489414\n",
              "5    4.317509\n",
              "6    4.093868\n",
              "7    3.937856\n",
              "8    3.837866\n",
              "9    3.724064\n",
              "10   3.632109\n",
              "11   3.534201\n",
              "12   3.505964\n",
              "13   3.406144\n",
              "14   3.390052\n",
              "15   3.311008\n",
              "16   3.245545\n",
              "17   3.224789\n",
              "18   3.160412\n",
              "19   3.131601"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3b0c8b3-72d9-4157-b4e7-894690d6d1d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13.630404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.435396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.694499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.939188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.489414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.317509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.093868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.937856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.837866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.724064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.632109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3.534201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.505964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.406144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.390052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3.311008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.245545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3.224789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3.160412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3.131601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3b0c8b3-72d9-4157-b4e7-894690d6d1d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3b0c8b3-72d9-4157-b4e7-894690d6d1d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3b0c8b3-72d9-4157-b4e7-894690d6d1d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization - Graph\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=[8, 4])\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, n_epoch - 1))\n",
        "plt.ylabel('Position')\n",
        "plt.title(\"Loss of GPT Model \")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "XycTtazri5vg",
        "outputId": "1480d414-7187-4e2d-d639-818558feabf4"
      },
      "id": "XycTtazri5vg",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}